#!/usr/bin/env python3
"""
fetch_pdfs_from_scholar.py
--------------------------
Download every freely available PDF listed on a Google Scholar profile.

Usage
-----
    python scripts/fetch_pdfs_from_scholar.py <SCHOLAR_USER_ID>

Example:
    python scripts/fetch_pdfs_from_scholar.py lhDYN_YAAAAJ

Notes
-----
* Only PDFs that Google Scholar exposes via an "[PDF]" link will be downloaded.
* Pay-walled papers usually have no public PDF link and are therefore skipped.
* Be considerate: the script pauses one second between downloads to avoid
  hammering remote servers.
* Requires: `pip install scholarly tqdm requests`

Author: Prasad P. Iyer (auto-generated by assistant)
"""

import sys
import time
import pathlib
import re
from typing import Optional
import json, urllib.parse

import requests
from tqdm import tqdm
from scholarly import scholarly

# ----------------------------------------------------------------------------
# Helper functions
# ----------------------------------------------------------------------------

def sanitize_filename(title: str) -> str:
    """Return a filesystem-safe filename derived from a paper title."""
    title = re.sub(r"[\\/:*?\"<>|]", "_", title)  # illegal NTFS chars
    title = re.sub(r"\s+", " ", title).strip()        # collapse spaces
    return title[:150]  # limit length to avoid OS issues


def download_pdf(url: str, dest: pathlib.Path, *, timeout: int = 30) -> bool:
    """Download *url* to *dest*.  Returns True on success, False otherwise."""
    try:
        hdrs = {"User-Agent": "Mozilla/5.0 (compatible; pdf-grabber/1.0)"}
        r = requests.get(url, timeout=timeout, headers=hdrs)
        r.raise_for_status()
        dest.write_bytes(r.content)
        return True
    except Exception as exc:
        tqdm.write(f"⚠️  {dest.name}: {exc}")
        return False


UNP_API = "https://api.unpaywall.org/v2/{}?email=YOUR_EMAIL@example.com"

def pdf_from_unpaywall(doi: str) -> str | None:
    if not doi:
        return None
    try:
        r = requests.get(UNP_API.format(urllib.parse.quote(doi)), timeout=20)
        data = r.json()
        loc = data.get("best_oa_location") or {}
        return loc.get("url_for_pdf")
    except Exception:
        return None


# ----------------------------------------------------------------------------
# Main script
# ----------------------------------------------------------------------------

def main() -> None:
    if len(sys.argv) != 2:
        sys.exit("Usage: python scripts/fetch_pdfs_from_scholar.py <SCHOLAR_USER_ID>")

    user_id: str = sys.argv[1].strip()
    save_dir = pathlib.Path("pdfs_from_scholar")
    save_dir.mkdir(exist_ok=True)

    print("Contacting Google Scholar …")
    author = scholarly.search_author_id(user_id)
    if not author:
        sys.exit("Error: user ID not found on Google Scholar.")

    author = scholarly.fill(author, sections=["publications"])
    publications = author.get("publications", [])
    print(f"Found {len(publications)} publications for {author.get('name', '(unknown)')}")

    for pub in tqdm(publications, unit="paper"):
        pub_filled = scholarly.fill(pub)
        bib = pub_filled.get("bib", {})
        title = sanitize_filename(bib.get("title", "untitled"))

        # 1) Preferred direct PDF link Google Scholar exposes
        pdf_url: Optional[str] = pub_filled.get("eprint_url")

        # 2) Fallback: the publication's main URL – occasionally is already a PDF
        if not pdf_url:
            pdf_url = pub_filled.get("pub_url")

        # 3) Another fallback: bib["url"] (rare)
        if not pdf_url:
            pdf_url = bib.get("url")

        if not pdf_url:
            continue  # nothing to try

        # Quick sanity check: is it likely a PDF? If not obvious, we'll HEAD it.
        if not pdf_url.lower().endswith(".pdf"):
            try:
                h = requests.head(pdf_url, allow_redirects=True, timeout=15)
                if h.headers.get("content-type", "").lower().startswith("application/pdf"):
                    pass  # okay!
                else:
                    continue  # not a PDF
            except Exception:
                continue  # skip on errors

        outfile = save_dir / f"{title}.pdf"
        if outfile.exists():
            continue  # already downloaded

        if download_pdf(pdf_url, outfile):
            # be polite: brief pause between downloads
            time.sleep(1)

    print(f"\n✓ Finished. PDFs saved in {save_dir.resolve()}")


if __name__ == "__main__":
    main() 